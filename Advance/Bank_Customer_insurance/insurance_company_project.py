# -*- coding: utf-8 -*-
"""Insurance_company_Project.ipynb
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1ey6u9A753pR4j295dovtdzJTR_qZCq7Q
"""

import pandas as pd
import numpy as np
from collections import Counter
import matplotlib.pyplot as plt
from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/Datasets_ML_AI_DL/Insurance_company_Churn_Modelling.csv')
df.head(5)
df = df.drop(["RowNumber","Surname","CustomerId"],axis=1)
df.head(1)
#df.shape

"""# Data visualization"""

from sklearn.preprocessing import LabelEncoder
geography = LabelEncoder()
gender = LabelEncoder()
df2=df
df2['Geography_n']=geography.fit_transform(df["Geography"])
df2['gender_n']=gender.fit_transform(df["Gender"])
df2.head(2)

print(df2.Geography_n)

plt.figure(figsize=(18,18))
plt.subplot(4,4,1)
plt.title("Age vs Active member")
plt.scatter(df.Age,df.IsActiveMember ,marker='*',color='red')
plt.subplot(4,4,2)
plt.title("Balance vs Active member")
plt.scatter(df.Balance,df.IsActiveMember ,marker='*',color='red')
plt.subplot(4,4,3)
plt.title("CreditScore vs Active member")
plt.scatter(df.CreditScore,df.IsActiveMember ,marker='*',color='red')
plt.subplot(4,4,4)
plt.title("EstimatedSalary vs Active member")
plt.scatter(df.EstimatedSalary,df.IsActiveMember ,marker='*',color='red')
plt.subplot(4,4,5)
plt.title("HasCrCard vs Active member")
plt.scatter(df.HasCrCard,df.IsActiveMember ,marker='*',color='red')
plt.subplot(4,4,6)
plt.title("Tenure vs Active member")
plt.scatter(df.Tenure,df.IsActiveMember ,marker='*',color='red')
plt.subplot(4,4,7)
plt.title("Geography vs Active member")
plt.scatter(df.Geography_n,df.IsActiveMember ,marker='*',color='red')
plt.subplot(4,4,8)
plt.title("Exited vs Active member")
plt.scatter(df.Exited,df.IsActiveMember ,marker='*',color='red')
plt.subplot(4,4,9)
plt.title("Country vs Active member")
plt.scatter(df2.Geography_n,df.IsActiveMember ,marker='*',color='red')
plt.subplot(4,4,10)
plt.title("Gender vs Active member")
plt.scatter(df2.gender_n,df.IsActiveMember ,marker='*',color='red')
plt.show()

df.describe()

"""# Feature values extraction
We can easily detect how much significant categorical major or minor values are in dataset using a simple histogram visualization.Some features have 2,3 major values some have huge values.
"""

df2.hist(bins=50 ,figsize=(20,15))
plt.show()

df2.info()

"""## Looking for Corelation functions

based on IsActiveMember we try to find corelation features.Positive values features are more corelated for IsActiveMember.If there value increses then IsActiveMember might be 1 .
"""

corr_matrix=df2.corr()
corr_matrix_sorted_values=corr_matrix['IsActiveMember'].sort_values(ascending=False)
print(corr_matrix_sorted_values)
corr_matrix_sorted_values.hist(bins=100,figsize=(5,5))
plt.legend("upper right")
plt.show()

"""# Finding Inactive account Tandancy based on Gender"""

gender = df2.groupby("Gender")["Gender"].count()
gender.head()

gender_array_data=gender.values
print(gender_array_data)

male=(gender_array_data[1]*100)/len(df2)
female=(gender_array_data[0]*100)/len(df2)
print(male)
print(female)

df3 = pd.DataFrame(df2, columns =['Gender','Geography','IsActiveMember' ])
df_new = df3[df3['IsActiveMember'] == 1]
df_new_gender = df_new.groupby("Gender")["Gender"].count().values
#print(df_new)
print(df_new_gender)

active_male = ((df_new_gender[1])*100)/5457
inactive_male =((5457-df_new_gender[1])*100)/5457
active_female = ((df_new_gender[0])*100)/4543
inactive_female =((4543-df_new_gender[0])*100)/4543
print(active_male)
print(inactive_male)

# defining labels
# portion covered by each label
ap1 = ['5457 male','4543 female']
ap2 = ['Active male','InActive male']
ap3 = ['Active Female','Inactive female']
slices = [male,female]
slices1 =[active_male,inactive_male]
slices2 = [active_female,inactive_female]
 # color for each label
colors = ['r', 'g']
colors2 = ['#339cff', 'y']
colors3 = ['#ff5733', '#9cff33']
# plotting the pie chart

plt.figure(figsize=(18,18))
plt.subplot(4,3,1)
plt.title("100% male and female user")
plt.pie(slices, labels = ap1, colors=colors,
        startangle=90, shadow = True, explode = (0,0.1),
        radius = 1.0, autopct = '%1.1f%%')
# plotting legend
plt.legend()
plt.subplot(4,3,2)
plt.title("Male user Active vs Inactive rate")
plt.pie(slices1, labels = ap2, colors=colors2,
        startangle=90, shadow = True, explode = (0,0.1),
        radius = 1.0, autopct = '%1.1f%%')
# plotting legend
plt.legend()
plt.subplot(4,3,3)
plt.title("Female user Active vs Inactive rate")
plt.pie(slices2, labels = ap3, colors=colors3,
        startangle=90, shadow = True, explode = (0,0.1),
        radius = 1.0, autopct = '%1.1f%%')
# plotting legend
plt.legend()
# showing the plot
plt.show()

"""# Finding Inactive account Tandancy according to Geography(Country)"""

df3.head()

geography_old_data = df3.groupby("Geography")["Geography"].count()
#geography_old_data
france_total = geography_old_data[0]
germany_total= geography_old_data [1]
spain_total = geography_old_data[2]
print(geography_old_data[0])

geography_new_data = df_new.groupby("Geography")["Geography"].count().values
#geography_new_data
france_new_active = geography_new_data[0]
france_new_inactive =france_total -france_new_active
germany_new_active= geography_new_data [1]
germany_new_inactive=germany_total-germany_new_active
spain_new_active = geography_new_data[2]
spain_new_inactive=spain_total-spain_new_active
print(france_new_inactive)

import matplotlib.pyplot as plt
 
# defining labels
activities = ['France', 'Germany', 'Spain']
activities02 = ['France Active', 'France inactive']
activities03 = ['Germany Active', 'Germany inactive']
activities04 = ['Spain Active', 'Spain inactive']
activities05 = ['France', 'Germany', 'Spain']
 
# portion covered by each label
slices = [france_total, germany_total,spain_total]
slices02 = [(france_new_active*100)/france_total,(france_new_inactive*100)/france_total]
slices03 = [germany_new_active/100,germany_new_inactive/100]
slices04 = [spain_new_active/100,spain_new_inactive/100]
slices05 = [(france_new_inactive*100)/france_total, (germany_new_inactive*100)/germany_total,(spain_new_inactive*100)/spain_total]

# color for each label
colors = ['r', 'y', 'g']
colors02 = ['#339cff', '#e9e60d']
colors03 = ['#e20de9', '#32e90d']
colors04 = ['#e90d74', '#19bb40']
colors05 = ['r', 'y', 'g']
 
# plotting the pie chart
plt.figure(figsize=(18,18))
plt.subplot(4,3,1)
plt.title("Total User Based On country")
plt.pie(slices, labels = activities, colors=colors,
        startangle=90,shadow = True, explode = (0.045,0.045,0.05),
        radius = 1.2, autopct = '%1.1f%%')
# plotting legend
plt.legend()

plt.subplot(4,3,2)
plt.title("Total Inactive User Based On country")
plt.pie(slices05, labels = activities05, colors=colors05,
        startangle=90,shadow = True, explode = (0.045,0.045,0.05),
        radius = 1.2, autopct = '%1.1f%%')
# plotting legend
plt.legend()

plt.subplot(4,3,3)
plt.title("France Active vs Inactive user")
plt.pie(slices02, labels = activities02, colors=colors02,
        startangle=90,shadow = True, explode = (0.045,0.045),
        radius = 1.2, autopct = '%1.1f%%')
# plotting legend
plt.legend()


plt.subplot(4,3,4)
plt.title("Germany  Active vs Inactive user")
plt.pie(slices03, labels = activities03, colors=colors03,
        startangle=90,shadow = True, explode = (0.045,0.045),
        radius = 1.2, autopct = '%1.1f%%')
# plotting legend
plt.legend()


plt.subplot(4,3,6)
plt.title("Spain  Active vs Inactive user")
plt.pie(slices04, labels = activities04, colors=colors04,
        startangle=90,shadow = True, explode = (0.045,0.045),
        radius = 1.2, autopct = '%1.1f%%')
# plotting legend
plt.legend()
# showing the plot
plt.show()

"""# AI modelling()

i)Logistic regression
ii)Decision Tree
iii)Random Forest
iv)

## Split data into X and Y
"""

from sklearn.model_selection import train_test_split
#df2.info()
X=df2.drop(["Geography","Gender","Exited","IsActiveMember"],axis=1)
Y=df2["IsActiveMember"]

x_train,x_test,y_train,y_test = train_test_split(X,Y,train_size=0.996,test_size=0.004)
print(y_test.values)
print(y_test.shape)

"""## `1.Linear regression Tree`"""

from sklearn.linear_model import LinearRegression,LogisticRegression
import pandas as pd
LRmodel = LogisticRegression()
LRmodel.fit(x_train,y_train)
lrpredict = LRmodel.predict(x_test)
#print(lrpredict)
ytest_val=y_test.values
ytest_val
df_ed = pd.DataFrame({'Actual': ytest_val.flatten(), 'Predicted': lrpredict.flatten()})
df_ed.plot(kind='bar',figsize=(15,15))
plt.show()

"""Let's find Errors\
Displaying errors\
Displaying errors
"""

from sklearn import metrics
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split

LMe=metrics.mean_absolute_error(y_test, lrpredict)
LMse=metrics.mean_squared_error(y_test, lrpredict)
LRMse=np.sqrt(metrics.mean_squared_error(y_test,lrpredict))
Lrt=metrics.r2_score(y_test,lrpredict)
LaccuracyScore = LRmodel.score (x_test,y_test)

print([LMe,LMse,LRMse,Lrt,LaccuracyScore])

"""## `2.Decision Tree`"""

from sklearn import tree
#Decission Trees
DTmodel = tree.DecisionTreeClassifier()
#Page 4 of 6
DTmodel.fit(x_train, y_train)
# testing
model_predictions = DTmodel.predict(x_test)
# accuracy of prediction
DMe = metrics.mean_absolute_error(y_test, model_predictions)
Dmse = metrics.mean_squared_error(y_test, model_predictions)
Dmsqt = np.sqrt(metrics.mean_squared_error(y_test,model_predictions))
Drt=metrics.r2_score(y_test,model_predictions)
DaccuracyScore = accuracy_score(y_test, model_predictions)
print([DMe,Dmse,Dmsqt,Drt,DaccuracyScore])

"""## `3.SVM`"""

from sklearn.svm import SVC

SVM_model = SVC()
SVM_model.fit(x_train, y_train)
svm_prediction = SVM_model.predict(x_test)
svm_me = metrics.mean_absolute_error(y_test, svm_prediction)
svm_mse = metrics.mean_squared_error(y_test, svm_prediction)
svm_msqt = np.sqrt(metrics.mean_squared_error(y_test,svm_prediction))
svm_rt=metrics.r2_score(y_test,svm_prediction)
svm_accuracyScore = accuracy_score(y_test,svm_prediction)
print([svm_me,svm_mse,svm_msqt,svm_accuracyScore])

"""## `4.Random Forest Tree`"""

from sklearn.ensemble import RandomForestClassifier

RFC_model = RandomForestClassifier()
RFC_model.fit(x_train, y_train)
RFC_prediction = RFC_model.predict(x_test)
RFC_me = metrics.mean_absolute_error(y_test, RFC_prediction)
RFC_mse = metrics.mean_squared_error(y_test, RFC_prediction)
RFC_msqt = np.sqrt(metrics.mean_squared_error(y_test,RFC_prediction))
RFC_rt=metrics.r2_score(y_test,RFC_prediction)
RFC_accuracyScore = accuracy_score(y_test,RFC_prediction)
print([RFC_me,RFC_mse,RFC_msqt,RFC_accuracyScore])

x = [LaccuracyScore,DaccuracyScore,svm_accuracyScore,RFC_accuracyScore]
df_acc_plot = pd.DataFrame({'Linear Accuracy': x[0].flatten(), 'Decision tree accuracy': x[1].flatten(),'SVM accuracy': x[2].flatten(),'Random Forest Cl. accuracy': x[2].flatten()})
df_acc_plot.plot(kind='bar',figsize=(10,8))
plt.show()